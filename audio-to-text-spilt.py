import openai
import os
import subprocess
from tkinter import Tk, filedialog
from pydub import AudioSegment
from mutagen.mp3 import MP3
import io
from dotenv import load_dotenv

# Setup ffmpeg for PyDub
os.environ["PATH"] += os.pathsep + r"C:/ffmpeg/bin"
AudioSegment.converter = r"C:/ffmpeg/bin/ffmpeg.exe"
AudioSegment.ffprobe = r"C:/ffmpeg/bin/ffprobe.exe"



# âœ… è¼‰å…¥ .env ä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if api_key:
    openai.api_key = api_key
    print(f"âœ… Import successfully, your API key is: {api_key}")
else:
    print("âŒ Failed to load OpenAI API key. Please check your .env file.")
    exit()


# Split audio into in-memory chunks (no saving)
def split_audio_to_memory(input_path, chunk_length_ms=5 * 60 * 1000):
    audio = AudioSegment.from_file(input_path)
    total_length = len(audio)
    chunks = []

    for i in range(0, total_length, chunk_length_ms):
        chunk = audio[i:i + chunk_length_ms]
        buffer = io.BytesIO()
        chunk.export(buffer, format="mp3", bitrate="192k")
        buffer.seek(0)
        chunks.append((buffer, len(chunk) / 1000 / 60))  # (BytesIO, minutes)
    
    return chunks

# File selection
Tk().withdraw()
file_path = filedialog.askopenfilename(title="é¸æ“‡éŸ³è¨Šæª”æ¡ˆ",
                                       filetypes=[("éŸ³è¨Šæ–‡ä»¶", "*.mp3;*.wav;*.flac;*.aac;*.ogg;*.m4a")])
if not file_path:
    print("âŒ æœªé¸æ“‡æª”æ¡ˆï¼Œç¨‹å¼çµæŸã€‚")
    exit()

file_dir, file_name = os.path.split(file_path)
file_base, _ = os.path.splitext(file_name)
converted_output_file = os.path.join(file_dir, file_base + "_converted.mp3")

# Convert to mp3
print("ğŸ” æ­£åœ¨è½‰æ›éŸ³è¨Šæ ¼å¼ç‚º mp3...")
subprocess.run([
    r"C:/ffmpeg/bin/ffmpeg.exe", "-y", "-i", file_path,
    "-c:a", "libmp3lame", "-b:a", "192k", converted_output_file
], check=True)
print("âœ… éŸ³è¨Šè½‰æ›å®Œæˆï¼")

# In-memory splitting
print("ğŸ”ª åˆ†å‰²éŸ³è¨Šä¸­...")
audio_chunks = split_audio_to_memory(converted_output_file)
print(f"âœ… å…±åˆ†æˆ {len(audio_chunks)} æ®µ")

# Transcribe each chunk
final_transcript = ""
total_cost = 0

for idx, (buffer, duration_min) in enumerate(audio_chunks, 1):
    print(f"ğŸ”Š è™•ç†ç¬¬ {idx} æ®µï¼ˆç´„ {round(duration_min, 2)} åˆ†é˜ï¼‰")
    response = openai.audio.transcriptions.create(
    model="whisper-1",
    file=("chunk.mp3", buffer, "audio/mpeg"),  # æŒ‡å®š fake filename + MIME type
    response_format="json"
    )
    final_transcript += f"[æ®µè½ {idx} é–‹å§‹]\n{response.text}\n\n"
    
    cost = round(duration_min * 0.006, 4)
    total_cost += cost
    print(f"ğŸ’° æ®µè½æˆæœ¬ï¼šç´„ ${cost}")

# Output final transcript
transcript_file = os.path.join(file_dir, file_base + "_transcript.txt")
with open(transcript_file, "w", encoding="utf-8") as f:
    f.write(final_transcript)

print(f"ğŸ“„ å·²è¼¸å‡ºå®Œæ•´è½‰éŒ„æ–‡å­—ï¼š{transcript_file}")
print(f"ğŸ’° é ä¼°ç¸½æˆæœ¬ï¼šç´„ ${round(total_cost, 4)} ç¾å…ƒ")
